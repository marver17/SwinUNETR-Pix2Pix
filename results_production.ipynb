{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4921baef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import sys\n",
    "import lightning as pl\n",
    "load_dotenv()  # legge il file .env\n",
    "repo_path = os.getenv(\"REPO_PATH\")\n",
    "sys.path.append(repo_path)\n",
    "os.chdir(repo_path)\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ad759c",
   "metadata": {},
   "source": [
    "## Analyze experiment result\n",
    "\n",
    "Unisce i risultati dai vari esperimenti unendoli in un unica tabella e creando una tabella di valori medi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f4167f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "def dotdict_constructor(loader, node):\n",
    "    \"\"\"Costruisce in modo sicuro un dizionario da un nodo di mappatura YAML, ignorando il tag personalizzato.\"\"\"\n",
    "    return loader.construct_mapping(node, deep=True)\n",
    "\n",
    "Loader = yaml.SafeLoader\n",
    "Loader.add_constructor('tag:yaml.org,2002:python/object:utils.util.DotDict', dotdict_constructor)\n",
    "\n",
    "def retrieve_hyperparameters(hparams_path: str) -> dict:\n",
    "    \"\"\"\n",
    "    Legge un file hparams.yaml di Pytorch Lightning, estrae il tipo di generatore\n",
    "    e la combinazione di loss utilizzate.\n",
    "\n",
    "    Args:\n",
    "        hparams_path (str): Il percorso del file hparams.yaml.\n",
    "\n",
    "    Returns:\n",
    "        dict: Un dizionario con le chiavi 'generator' e 'loss'.\n",
    "              Restituisce un dizionario vuoto se il file non viene trovato,\n",
    "              è vuoto, ha una struttura inattesa o si verifica un errore.\n",
    "    \"\"\"\n",
    "    extracted_data = {}\n",
    "\n",
    "    try:\n",
    "        with open(hparams_path, 'r') as file:\n",
    "            # Usa il loader personalizzato per analizzare correttamente il file senza errori.\n",
    "            hparams = yaml.load(file, Loader=Loader)\n",
    "\n",
    "        if not hparams or 'opt' not in hparams:\n",
    "            print(f\"Attenzione: Il file YAML '{hparams_path}' è vuoto o non ha la struttura attesa (manca la chiave 'opt').\")\n",
    "            return {}\n",
    "\n",
    "        generator = hparams.get('opt', {}).get('model', {}).get('generator', {}).get('netG', 'Non specificato')\n",
    "\n",
    "        losses_config = hparams.get('opt', {}).get('training', {}).get('losses', {})\n",
    "        \n",
    "        active_losses = [\n",
    "            key.replace('lambda_', '').upper()\n",
    "            for key, value in losses_config.items()\n",
    "            if key.startswith('lambda_') and isinstance(value, (int, float)) and value > 0\n",
    "        ]\n",
    "        \n",
    "        loss_str = '+'.join(sorted(active_losses)) if active_losses else 'Non specificata'\n",
    "\n",
    "        extracted_data = {\n",
    "            'generator': generator,\n",
    "            'loss': loss_str\n",
    "        }\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Errore: Il file non è stato trovato al percorso '{hparams_path}'\")\n",
    "    except (yaml.YAMLError, AttributeError) as e:\n",
    "        print(f\"Errore durante il parsing del file YAML '{hparams_path}': {e}\")\n",
    "\n",
    "    return extracted_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f33b4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def read_metrics_from_json(file_path: str) -> dict:\n",
    "    \"\"\"\n",
    "    Legge un file JSON contenente metriche di valutazione e le restituisce.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Il percorso del file JSON da leggere.  \n",
    "\n",
    "    Returns:\n",
    "        dict: Un dizionario contenente le metriche lette dal file.\n",
    "              Restituisce un dizionario vuoto se il file non viene trovato,\n",
    "              non è un JSON valido o si verifica un altro errore di lettura.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r') as f:\n",
    "            metrics = json.load(f)\n",
    "        return metrics\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Errore: Il file non è stato trovato al percorso '{file_path}'\")\n",
    "        return {}\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Errore: Il file '{file_path}' non contiene un JSON valido o è corrotto.\")\n",
    "        return {}\n",
    "    except Exception as e:\n",
    "        print(f\"Si è verificato un errore inatteso durante la lettura di '{file_path}': {e}\")\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a82de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_experiment_results( main_path: str, \n",
    "                                testing_datasets: list[str],\n",
    "                                metrics_to_analyze: list[str] = ['MAE', 'PSNR', 'SSIM', 'MM-SSIM'], \n",
    "                                outlier_metric: str = 'SSIM' ) -> tuple[dict, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        main_path (str): Percorso principale contenente le directory delle versioni.\n",
    "        testing_datasets (list[str]): Lista dei nomi dei dataset di test.\n",
    "        metrics_to_analyze (list[str], optional): Lista delle metriche da analizzare.\n",
    "        outlier_metric (str, optional): Metrica su cui basare la rimozione degli outlier.\n",
    "\n",
    "    Returns:\n",
    "        tuple[dict, pd.DataFrame]:\n",
    "            - Dizionario con i risultati dettagliati (grezzi) per ogni esperimento.\n",
    "            - DataFrame riassuntivo con le medie (senza outlier).\n",
    "    \"\"\"\n",
    "    all_results = []\n",
    "\n",
    "    # 1. Standardizza i parametri di input in MAIUSCOLO per coerenza\n",
    "    metrics_to_analyze_upper = [m.upper() for m in metrics_to_analyze]\n",
    "    outlier_metric_upper = outlier_metric.upper()\n",
    "\n",
    "    if outlier_metric_upper not in metrics_to_analyze_upper:\n",
    "        raise ValueError(f\"La metrica per l'outlier '{outlier_metric}' deve essere in 'metrics_to_analyze'.\")\n",
    "\n",
    "    print(f\"Avvio analisi in: {main_path}\")\n",
    "    for version_folder in sorted(os.listdir(main_path)):\n",
    "        version_path = os.path.join(main_path, version_folder)\n",
    "        if not os.path.isdir(version_path) or not version_folder.startswith('version_'):\n",
    "            continue\n",
    "        \n",
    "        # ... (recupero hparams) ...\n",
    "        hparams_path = os.path.join(version_path, \"hparams.yaml\")\n",
    "        h_params = retrieve_hyperparameters(hparams_path)\n",
    "        if not h_params: continue\n",
    "\n",
    "        test_results_base_path = os.path.join(version_path, \"test_results\")\n",
    "        for test_dataset in testing_datasets:\n",
    "            dataset_path = os.path.join(test_results_base_path, test_dataset)\n",
    "            if not os.path.isdir(dataset_path): continue\n",
    "\n",
    "            for subject in os.listdir(dataset_path):\n",
    "                subject_path = os.path.join(dataset_path, subject)\n",
    "                if not os.path.isdir(subject_path): continue\n",
    "                \n",
    "                metrics_path = os.path.join(subject_path, \"metrics.json\")\n",
    "                metrics = read_metrics_from_json(metrics_path)\n",
    "\n",
    "                if metrics:\n",
    "                    standardized_metrics = {key.upper(): value for key, value in metrics.items()}\n",
    "\n",
    "                    record = {\n",
    "                        'VERSION': version_folder,\n",
    "                        'GENERATOR': h_params.get('generator', 'N/A'),\n",
    "                        'LOSS': h_params.get('loss', 'N/A'),\n",
    "                        'TEST_DATASET': test_dataset,\n",
    "                        'SUBJECT': subject,\n",
    "                        **standardized_metrics  # Usa il dizionario con le chiavi già corrette\n",
    "                    }\n",
    "                    all_results.append(record)\n",
    "\n",
    "    if not all_results:\n",
    "        print(\"Nessun risultato trovato. Restituisco strutture vuote.\")\n",
    "        return {}, pd.DataFrame()\n",
    "\n",
    "    master_df = pd.DataFrame(all_results)\n",
    "\n",
    "\n",
    "    # Blocco di codice corretto e completo per la rimozione outlier\n",
    "    outlier_free_df = master_df.copy()\n",
    "    if outlier_metric_upper in outlier_free_df.columns:\n",
    "        print(f\"\\nRimozione outlier basata su '{outlier_metric_upper}'...\")\n",
    "        \n",
    "        # Assicurati che queste due righe siano identiche nel tuo codice\n",
    "        q1 = master_df.groupby(['VERSION', 'TEST_DATASET'])[outlier_metric_upper].transform('quantile', 0.25)\n",
    "        q3 = master_df.groupby(['VERSION', 'TEST_DATASET'])[outlier_metric_upper].transform('quantile', 0.75)\n",
    "        \n",
    "        iqr = q3 - q1\n",
    "        lower_bound = q1 - 1.5 * iqr\n",
    "        \n",
    "        is_not_outlier = master_df[outlier_metric_upper] >= lower_bound\n",
    "        outlier_free_df = master_df[is_not_outlier]\n",
    "        \n",
    "        print(f\"Analisi completata. Rimossi {len(master_df) - len(outlier_free_df)} record su {len(master_df)}.\")\n",
    "    else:\n",
    "        print(f\"\\nAttenzione: La metrica per outlier '{outlier_metric_upper}' non trovata. Salto la rimozione.\")\n",
    "    summary_df = pd.DataFrame()\n",
    "    final_metrics_to_analyze = [m for m in metrics_to_analyze_upper if m in outlier_free_df.columns]\n",
    "\n",
    "    if not final_metrics_to_analyze:\n",
    "        print(\"Nessuna delle metriche specificate è stata trovata nei dati.\")\n",
    "    else:\n",
    "        grouping_cols = ['VERSION', 'GENERATOR', 'LOSS', 'TEST_DATASET']\n",
    "        \n",
    "        # --- INIZIO MODIFICA ---\n",
    "        \n",
    "        # 1. Calcola sia la media che la deviazione standard con .agg()\n",
    "        # Questo crea un DataFrame con colonne multi-livello (es. 'MAE' -> 'mean', 'std')\n",
    "        summary_stats = outlier_free_df.groupby(grouping_cols)[final_metrics_to_analyze].agg(['mean', 'std'])\n",
    "\n",
    "        # 2. Formatta le colonne delle metriche per mostrare \"media ± std\"\n",
    "        for metric in final_metrics_to_analyze:\n",
    "            # Estrai le colonne di media e std per la metrica corrente\n",
    "            mean_col = (metric, 'mean')\n",
    "            std_col = (metric, 'std')\n",
    "            \n",
    "            # Crea una nuova colonna formattata (es. \"0.1234 ± 0.0123\")\n",
    "            # Usiamo .map() per applicare la formattazione a tutta la serie\n",
    "            summary_stats[metric] = (\n",
    "                summary_stats[mean_col].map('{:.4f}'.format) + \n",
    "                ' ± ' + \n",
    "                summary_stats[std_col].map('{:.4f}'.format)\n",
    "            )\n",
    "\n",
    "        # 3. Seleziona solo le colonne finali (quelle formattate) e reimposta l'indice\n",
    "        # Il risultato finale avrà le colonne originali delle metriche, ma con i valori formattati.\n",
    "            summary_df = outlier_free_df.groupby(grouping_cols)[final_metrics_to_analyze].agg(\n",
    "                lambda s: f\"{s.mean():.4f} \\u00B1 {s.std():.4f}\"\n",
    "            ).reset_index()\n",
    "\n",
    "\n",
    "    individual_dfs = {version: group for version, group in master_df.groupby('VERSION')}\n",
    "\n",
    "    return individual_dfs, summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d616d22f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avvio analisi in: lightning_logs/MRtoCT\n",
      "\n",
      "Rimozione outlier basata su 'SSIM'...\n",
      "Analisi completata. Rimossi 79 record su 2296.\n"
     ]
    }
   ],
   "source": [
    "MAIN_EXPERIMENT_PATH = 'lightning_logs/MRtoCT'\n",
    "TESTING_DATASETS = [\"RF\", \"SynthRAD2023\"]\n",
    "\n",
    "detailed_results, summary_results = analyze_experiment_results(MAIN_EXPERIMENT_PATH, TESTING_DATASETS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fd8ead21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VERSION</th>\n",
       "      <th>GENERATOR</th>\n",
       "      <th>LOSS</th>\n",
       "      <th>TEST_DATASET</th>\n",
       "      <th>MAE</th>\n",
       "      <th>PSNR</th>\n",
       "      <th>SSIM</th>\n",
       "      <th>MM-SSIM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>version_1</td>\n",
       "      <td>swinunetr_128</td>\n",
       "      <td>L1+PERCEPTUAL+STRUCTURAL</td>\n",
       "      <td>RF</td>\n",
       "      <td>0.0241 ± 0.0094</td>\n",
       "      <td>26.0741 ± 3.3469</td>\n",
       "      <td>0.9340 ± 0.0231</td>\n",
       "      <td>0.9480 ± 0.0169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>version_1</td>\n",
       "      <td>swinunetr_128</td>\n",
       "      <td>L1+PERCEPTUAL+STRUCTURAL</td>\n",
       "      <td>SynthRAD2023</td>\n",
       "      <td>0.0243 ± 0.0079</td>\n",
       "      <td>24.5501 ± 1.8223</td>\n",
       "      <td>0.8635 ± 0.0248</td>\n",
       "      <td>0.8409 ± 0.0350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>version_2</td>\n",
       "      <td>unet_128</td>\n",
       "      <td>L1+PERCEPTUAL+STRUCTURAL</td>\n",
       "      <td>RF</td>\n",
       "      <td>0.0310 ± 0.0114</td>\n",
       "      <td>24.2366 ± 3.0074</td>\n",
       "      <td>0.8359 ± 0.0599</td>\n",
       "      <td>0.9201 ± 0.0198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>version_2</td>\n",
       "      <td>unet_128</td>\n",
       "      <td>L1+PERCEPTUAL+STRUCTURAL</td>\n",
       "      <td>SynthRAD2023</td>\n",
       "      <td>0.0251 ± 0.0112</td>\n",
       "      <td>24.6157 ± 2.3800</td>\n",
       "      <td>0.8410 ± 0.0361</td>\n",
       "      <td>0.8418 ± 0.0358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>version_3</td>\n",
       "      <td>swinunetr_128</td>\n",
       "      <td>L1+STRUCTURAL</td>\n",
       "      <td>RF</td>\n",
       "      <td>0.0287 ± 0.0127</td>\n",
       "      <td>25.1301 ± 4.1493</td>\n",
       "      <td>0.9387 ± 0.0215</td>\n",
       "      <td>0.9487 ± 0.0173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>version_3</td>\n",
       "      <td>swinunetr_128</td>\n",
       "      <td>L1+STRUCTURAL</td>\n",
       "      <td>SynthRAD2023</td>\n",
       "      <td>0.0234 ± 0.0113</td>\n",
       "      <td>24.9389 ± 2.4717</td>\n",
       "      <td>0.8729 ± 0.0244</td>\n",
       "      <td>0.8566 ± 0.0364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>version_4</td>\n",
       "      <td>unet_128</td>\n",
       "      <td>L1+STRUCTURAL</td>\n",
       "      <td>RF</td>\n",
       "      <td>0.0300 ± 0.0114</td>\n",
       "      <td>24.1359 ± 3.1221</td>\n",
       "      <td>0.8749 ± 0.0446</td>\n",
       "      <td>0.9220 ± 0.0202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>version_4</td>\n",
       "      <td>unet_128</td>\n",
       "      <td>L1+STRUCTURAL</td>\n",
       "      <td>SynthRAD2023</td>\n",
       "      <td>0.0236 ± 0.0112</td>\n",
       "      <td>25.0319 ± 2.5552</td>\n",
       "      <td>0.8523 ± 0.0354</td>\n",
       "      <td>0.8485 ± 0.0354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>version_5</td>\n",
       "      <td>swinunetr_128</td>\n",
       "      <td>L1+PERCEPTUAL</td>\n",
       "      <td>RF</td>\n",
       "      <td>0.0232 ± 0.0086</td>\n",
       "      <td>26.0256 ± 2.9827</td>\n",
       "      <td>0.9118 ± 0.0269</td>\n",
       "      <td>0.9358 ± 0.0192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>version_5</td>\n",
       "      <td>swinunetr_128</td>\n",
       "      <td>L1+PERCEPTUAL</td>\n",
       "      <td>SynthRAD2023</td>\n",
       "      <td>0.0229 ± 0.0103</td>\n",
       "      <td>24.9720 ± 2.3123</td>\n",
       "      <td>0.8625 ± 0.0269</td>\n",
       "      <td>0.8486 ± 0.0370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>version_6</td>\n",
       "      <td>unet_128</td>\n",
       "      <td>L1+PERCEPTUAL</td>\n",
       "      <td>RF</td>\n",
       "      <td>0.0376 ± 0.0134</td>\n",
       "      <td>23.5073 ± 3.5469</td>\n",
       "      <td>0.7161 ± 0.0935</td>\n",
       "      <td>0.9017 ± 0.0282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>version_6</td>\n",
       "      <td>unet_128</td>\n",
       "      <td>L1+PERCEPTUAL</td>\n",
       "      <td>SynthRAD2023</td>\n",
       "      <td>0.0285 ± 0.0120</td>\n",
       "      <td>24.4840 ± 2.4689</td>\n",
       "      <td>0.7196 ± 0.0977</td>\n",
       "      <td>0.8372 ± 0.0375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>version_7</td>\n",
       "      <td>swinunetr_128</td>\n",
       "      <td>L1</td>\n",
       "      <td>RF</td>\n",
       "      <td>0.0228 ± 0.0081</td>\n",
       "      <td>26.0640 ± 3.0503</td>\n",
       "      <td>0.9250 ± 0.0191</td>\n",
       "      <td>0.9309 ± 0.0198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>version_7</td>\n",
       "      <td>swinunetr_128</td>\n",
       "      <td>L1</td>\n",
       "      <td>SynthRAD2023</td>\n",
       "      <td>0.0241 ± 0.0086</td>\n",
       "      <td>24.6676 ± 2.0908</td>\n",
       "      <td>0.8546 ± 0.0250</td>\n",
       "      <td>0.8347 ± 0.0361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>version_8</td>\n",
       "      <td>unet_128</td>\n",
       "      <td>L1</td>\n",
       "      <td>RF</td>\n",
       "      <td>0.0304 ± 0.0117</td>\n",
       "      <td>24.6552 ± 3.4226</td>\n",
       "      <td>0.8403 ± 0.0640</td>\n",
       "      <td>0.9274 ± 0.0197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>version_8</td>\n",
       "      <td>unet_128</td>\n",
       "      <td>L1</td>\n",
       "      <td>SynthRAD2023</td>\n",
       "      <td>0.0239 ± 0.0114</td>\n",
       "      <td>25.0054 ± 2.5355</td>\n",
       "      <td>0.8391 ± 0.0454</td>\n",
       "      <td>0.8464 ± 0.0359</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      VERSION      GENERATOR                      LOSS  TEST_DATASET  \\\n",
       "0   version_1  swinunetr_128  L1+PERCEPTUAL+STRUCTURAL            RF   \n",
       "1   version_1  swinunetr_128  L1+PERCEPTUAL+STRUCTURAL  SynthRAD2023   \n",
       "2   version_2       unet_128  L1+PERCEPTUAL+STRUCTURAL            RF   \n",
       "3   version_2       unet_128  L1+PERCEPTUAL+STRUCTURAL  SynthRAD2023   \n",
       "4   version_3  swinunetr_128             L1+STRUCTURAL            RF   \n",
       "5   version_3  swinunetr_128             L1+STRUCTURAL  SynthRAD2023   \n",
       "6   version_4       unet_128             L1+STRUCTURAL            RF   \n",
       "7   version_4       unet_128             L1+STRUCTURAL  SynthRAD2023   \n",
       "8   version_5  swinunetr_128             L1+PERCEPTUAL            RF   \n",
       "9   version_5  swinunetr_128             L1+PERCEPTUAL  SynthRAD2023   \n",
       "10  version_6       unet_128             L1+PERCEPTUAL            RF   \n",
       "11  version_6       unet_128             L1+PERCEPTUAL  SynthRAD2023   \n",
       "12  version_7  swinunetr_128                        L1            RF   \n",
       "13  version_7  swinunetr_128                        L1  SynthRAD2023   \n",
       "14  version_8       unet_128                        L1            RF   \n",
       "15  version_8       unet_128                        L1  SynthRAD2023   \n",
       "\n",
       "                MAE              PSNR             SSIM          MM-SSIM  \n",
       "0   0.0241 ± 0.0094  26.0741 ± 3.3469  0.9340 ± 0.0231  0.9480 ± 0.0169  \n",
       "1   0.0243 ± 0.0079  24.5501 ± 1.8223  0.8635 ± 0.0248  0.8409 ± 0.0350  \n",
       "2   0.0310 ± 0.0114  24.2366 ± 3.0074  0.8359 ± 0.0599  0.9201 ± 0.0198  \n",
       "3   0.0251 ± 0.0112  24.6157 ± 2.3800  0.8410 ± 0.0361  0.8418 ± 0.0358  \n",
       "4   0.0287 ± 0.0127  25.1301 ± 4.1493  0.9387 ± 0.0215  0.9487 ± 0.0173  \n",
       "5   0.0234 ± 0.0113  24.9389 ± 2.4717  0.8729 ± 0.0244  0.8566 ± 0.0364  \n",
       "6   0.0300 ± 0.0114  24.1359 ± 3.1221  0.8749 ± 0.0446  0.9220 ± 0.0202  \n",
       "7   0.0236 ± 0.0112  25.0319 ± 2.5552  0.8523 ± 0.0354  0.8485 ± 0.0354  \n",
       "8   0.0232 ± 0.0086  26.0256 ± 2.9827  0.9118 ± 0.0269  0.9358 ± 0.0192  \n",
       "9   0.0229 ± 0.0103  24.9720 ± 2.3123  0.8625 ± 0.0269  0.8486 ± 0.0370  \n",
       "10  0.0376 ± 0.0134  23.5073 ± 3.5469  0.7161 ± 0.0935  0.9017 ± 0.0282  \n",
       "11  0.0285 ± 0.0120  24.4840 ± 2.4689  0.7196 ± 0.0977  0.8372 ± 0.0375  \n",
       "12  0.0228 ± 0.0081  26.0640 ± 3.0503  0.9250 ± 0.0191  0.9309 ± 0.0198  \n",
       "13  0.0241 ± 0.0086  24.6676 ± 2.0908  0.8546 ± 0.0250  0.8347 ± 0.0361  \n",
       "14  0.0304 ± 0.0117  24.6552 ± 3.4226  0.8403 ± 0.0640  0.9274 ± 0.0197  \n",
       "15  0.0239 ± 0.0114  25.0054 ± 2.5355  0.8391 ± 0.0454  0.8464 ± 0.0359  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10fc3365",
   "metadata": {},
   "source": [
    "## Produce Latex table \n",
    "\n",
    "Partendo dal dataframe vado a creare una tabella importabile direttamente in latex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "702d67cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_latex_table_from_dataframe(\n",
    "    summary_results: pd.DataFrame,\n",
    "    metrics=None,\n",
    "    metric_headers=None,\n",
    "    dataset_order=None,\n",
    "    caption=\"Confronto delle metriche di performance per diversi generatori e combinazioni di loss.\",\n",
    "    label=\"tab:generation_metrics\",\n",
    "    max_loss_len=20\n",
    ") -> str:\n",
    "    import textwrap\n",
    "    import re\n",
    "    from collections import OrderedDict\n",
    "\n",
    "    # --- Parametri di default ---\n",
    "    if metrics is None:\n",
    "        metrics = [\"MAE\", \"MM-SSIM\", \"PSNR\", \"SSIM\"]\n",
    "\n",
    "    if metric_headers is None:\n",
    "        metric_headers = OrderedDict([\n",
    "            ('MAE', 'MAE $\\\\downarrow$'),\n",
    "            ('MM-SSIM', 'MM-SSIM $\\\\uparrow$'),\n",
    "            ('PSNR', 'PSNR $\\\\uparrow$'),\n",
    "            ('SSIM', 'SSIM $\\\\uparrow$')\n",
    "        ])\n",
    "\n",
    "    df = summary_results.copy()\n",
    "\n",
    "    # Normalizza i nomi delle colonne\n",
    "    col_map = {c.lower().strip(): c for c in df.columns}\n",
    "    rename_dict = {}\n",
    "    if 'generator' not in col_map:\n",
    "        raise ValueError(f\"Colonna 'generator' non trovata. Colonne disponibili: {list(df.columns)}\")\n",
    "    if 'loss' not in col_map:\n",
    "        raise ValueError(f\"Colonna 'loss' non trovata. Colonne disponibili: {list(df.columns)}\")\n",
    "    if 'test_dataset' not in col_map and 'dataset' not in col_map:\n",
    "        raise ValueError(f\"Colonna 'test_dataset' o 'dataset' non trovata. Colonne disponibili: {list(df.columns)}\")\n",
    "\n",
    "    rename_dict[col_map['generator']] = 'generator'\n",
    "    rename_dict[col_map['loss']] = 'loss'\n",
    "    if 'test_dataset' in col_map:\n",
    "        rename_dict[col_map['test_dataset']] = 'test_dataset'\n",
    "    else:\n",
    "        rename_dict[col_map['dataset']] = 'test_dataset'\n",
    "\n",
    "    df = df.rename(columns=rename_dict)\n",
    "\n",
    "    # Normalizzo generator e loss\n",
    "    df['generator'] = df['generator'].astype(str).str.upper().str.strip()\n",
    "    df['loss'] = df['loss'].astype(str).str.upper().str.strip()\n",
    "\n",
    "    # Assicuro metriche in uppercase\n",
    "    metrics = [m.upper() for m in metrics]\n",
    "    metric_headers = {m.upper(): v for m, v in metric_headers.items()}\n",
    "\n",
    "    # Ordine dataset\n",
    "    if dataset_order:\n",
    "        lower_map = {d.lower(): d for d in dataset_order}\n",
    "        df['dataset_order'] = pd.Categorical(\n",
    "            df['test_dataset'].astype(str).str.lower(),\n",
    "            categories=[d.lower() for d in dataset_order],\n",
    "            ordered=True\n",
    "        )\n",
    "        dataset_display_map = {d.lower(): lower_map[d.lower()] for d in lower_map}\n",
    "    else:\n",
    "        df['dataset_order'] = df['test_dataset'].astype(str).str.lower()\n",
    "        dataset_display_map = {d.lower(): d for d in df['test_dataset'].unique()}\n",
    "\n",
    "    df['loss_order'] = df['loss'].str.count(r'\\+')\n",
    "    df = df.sort_values(by=['dataset_order', 'loss_order']).reset_index(drop=True)\n",
    "\n",
    "    # Pivot senza calcolo media\n",
    "    df_pivot = df.pivot_table(\n",
    "        index=['test_dataset', 'loss'],\n",
    "        columns='generator',\n",
    "        values=metrics,\n",
    "        aggfunc=lambda x: x.iloc[0]\n",
    "    ).swaplevel(0, 1, axis=1).sort_index(axis=1)\n",
    "\n",
    "    generators = df_pivot.columns.get_level_values(0).unique().tolist()\n",
    "\n",
    "    latex = []\n",
    "    latex.append(\"\\\\begin{table*}[htbp]\")\n",
    "    latex.append(\"    \\\\centering\")\n",
    "    latex.append(\"    \\\\small\")  # riduce la dimensione del font\n",
    "    latex.append(\"    \\\\renewcommand{\\\\arraystretch}{1.2}\")\n",
    "    latex.append(\"    \\\\setlength{\\\\tabcolsep}{4pt}\")\n",
    "    latex.append(f\"    \\\\caption{{{caption}}}\")\n",
    "    latex.append(f\"    \\\\label{{{label}}}\")\n",
    "    latex.append(\"    \\\\begin{tabular}{l\" + \"c\" * (len(generators) * len(metrics)) + \"}\")\n",
    "    latex.append(\"        \\\\toprule\")\n",
    "\n",
    "    # Header generatori\n",
    "    latex.append(\"        \\\\multirow{2}{*}{Loss Function}\" + \"\".join(\n",
    "        [f\" & \\\\multicolumn{{{len(metrics)}}}{{c}}{{{gen}}}\" for gen in generators]\n",
    "    ) + \" \\\\\\\\\")\n",
    "    cmid = []\n",
    "    for i in range(len(generators)):\n",
    "        start = 2 + i * len(metrics)\n",
    "        end = start + len(metrics) - 1\n",
    "        cmid.append(f\"\\\\cmidrule(lr){{{start}-{end}}}\")\n",
    "    latex.append(\"        \" + \" \".join(cmid))\n",
    "\n",
    "    # Header metriche\n",
    "    latex.append(\"         \" + \"\".join(\n",
    "        [f\" & {metric_headers[m]}\" for _ in generators for m in metrics]\n",
    "    ) + \" \\\\\\\\\")\n",
    "    latex.append(\"        \\\\midrule\")\n",
    "\n",
    "    # Corpo tabella\n",
    "    last_dataset = None\n",
    "    for (dataset, loss), row in df_pivot.iterrows():\n",
    "        dataset_lower = str(dataset).lower()\n",
    "        if dataset_lower != last_dataset:\n",
    "            if last_dataset is not None:\n",
    "                latex.append(\"        \\\\midrule\")\n",
    "            latex.append(f\"        \\\\\\\\[ -0.8em ]\")\n",
    "            latex.append(f\"        \\\\multicolumn{{{1 + len(generators)*len(metrics)}}}{{c}}{{\\\\textbf{{{dataset_display_map[dataset_lower]}}}}} \\\\\\\\\")\n",
    "            latex.append(f\"        \\\\\\\\[ -0.5em ]\")\n",
    "            last_dataset = dataset_lower\n",
    "\n",
    "        # Spezzatura nome loss\n",
    "        loss_fmt = loss.replace('+', ' + ')\n",
    "        if len(loss_fmt) > max_loss_len:\n",
    "            loss_fmt = \"\\\\makecell[l]{\" + \" \\\\\\\\ \".join(textwrap.wrap(loss_fmt, max_loss_len)) + \"}\"\n",
    "\n",
    "        # Funzione di formattazione valori con std su riga separata\n",
    "        def format_val(val):\n",
    "            if pd.isnull(val):\n",
    "                return \"-\"\n",
    "            if isinstance(val, (int, float)):\n",
    "                return f\"{val:.3f}\"\n",
    "            if isinstance(val, str):\n",
    "                match = re.match(r\"\\s*([+-]?\\d*\\.?\\d+)\\s*(?:±|\\+?-)\\s*([+-]?\\d*\\.?\\d+)\\s*\", val)\n",
    "                if match:\n",
    "                    mean, std = match.groups()\n",
    "                    try:\n",
    "                        return f\"\\\\makecell{{{float(mean):.3f} \\\\\\\\ {float(std):.3f}}}\"\n",
    "                    except ValueError:\n",
    "                        return val\n",
    "                return val\n",
    "            return str(val)\n",
    "\n",
    "        values = [format_val(val) for val in row.values]\n",
    "        latex.append(f\"        {loss_fmt} & \" + \" & \".join(values) + \" \\\\\\\\\")\n",
    "\n",
    "    latex.append(\"        \\\\bottomrule\")\n",
    "    latex.append(\"    \\\\end{tabular}\")\n",
    "    latex.append(\"\\\\end{table*}\")\n",
    "\n",
    "    return \"\\n\".join(latex)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e17d5099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table*}[htbp]\n",
      "    \\centering\n",
      "    \\small\n",
      "    \\renewcommand{\\arraystretch}{1.2}\n",
      "    \\setlength{\\tabcolsep}{4pt}\n",
      "    \\caption{Confronto delle metriche di performance per diversi generatori e combinazioni di loss.}\n",
      "    \\label{tab:generation_metrics}\n",
      "    \\begin{tabular}{lcccccccc}\n",
      "        \\toprule\n",
      "        \\multirow{2}{*}{Loss Function} & \\multicolumn{4}{c}{SWINUNETR_128} & \\multicolumn{4}{c}{UNET_128} \\\\\n",
      "        \\cmidrule(lr){2-5} \\cmidrule(lr){6-9}\n",
      "          & MAE $\\downarrow$ & MM-SSIM $\\uparrow$ & PSNR $\\uparrow$ & SSIM $\\uparrow$ & MAE $\\downarrow$ & MM-SSIM $\\uparrow$ & PSNR $\\uparrow$ & SSIM $\\uparrow$ \\\\\n",
      "        \\midrule\n",
      "        \\\\[ -0.8em ]\n",
      "        \\multicolumn{9}{c}{\\textbf{RF}} \\\\\n",
      "        \\\\[ -0.5em ]\n",
      "        L1 & \\makecell{0.023 \\\\ 0.008} & \\makecell{0.931 \\\\ 0.020} & \\makecell{26.064 \\\\ 3.050} & \\makecell{0.925 \\\\ 0.019} & \\makecell{0.030 \\\\ 0.012} & \\makecell{0.927 \\\\ 0.020} & \\makecell{24.655 \\\\ 3.423} & \\makecell{0.840 \\\\ 0.064} \\\\\n",
      "        L1 + PERCEPTUAL & \\makecell{0.023 \\\\ 0.009} & \\makecell{0.936 \\\\ 0.019} & \\makecell{26.026 \\\\ 2.983} & \\makecell{0.912 \\\\ 0.027} & \\makecell{0.038 \\\\ 0.013} & \\makecell{0.902 \\\\ 0.028} & \\makecell{23.507 \\\\ 3.547} & \\makecell{0.716 \\\\ 0.093} \\\\\n",
      "        \\makecell[l]{L1 + PERCEPTUAL + \\\\ STRUCTURAL} & \\makecell{0.024 \\\\ 0.009} & \\makecell{0.948 \\\\ 0.017} & \\makecell{26.074 \\\\ 3.347} & \\makecell{0.934 \\\\ 0.023} & \\makecell{0.031 \\\\ 0.011} & \\makecell{0.920 \\\\ 0.020} & \\makecell{24.237 \\\\ 3.007} & \\makecell{0.836 \\\\ 0.060} \\\\\n",
      "        L1 + STRUCTURAL & \\makecell{0.029 \\\\ 0.013} & \\makecell{0.949 \\\\ 0.017} & \\makecell{25.130 \\\\ 4.149} & \\makecell{0.939 \\\\ 0.021} & \\makecell{0.030 \\\\ 0.011} & \\makecell{0.922 \\\\ 0.020} & \\makecell{24.136 \\\\ 3.122} & \\makecell{0.875 \\\\ 0.045} \\\\\n",
      "        \\midrule\n",
      "        \\\\[ -0.8em ]\n",
      "        \\multicolumn{9}{c}{\\textbf{SynthRAD2023}} \\\\\n",
      "        \\\\[ -0.5em ]\n",
      "        L1 & \\makecell{0.024 \\\\ 0.009} & \\makecell{0.835 \\\\ 0.036} & \\makecell{24.668 \\\\ 2.091} & \\makecell{0.855 \\\\ 0.025} & \\makecell{0.024 \\\\ 0.011} & \\makecell{0.846 \\\\ 0.036} & \\makecell{25.005 \\\\ 2.535} & \\makecell{0.839 \\\\ 0.045} \\\\\n",
      "        L1 + PERCEPTUAL & \\makecell{0.023 \\\\ 0.010} & \\makecell{0.849 \\\\ 0.037} & \\makecell{24.972 \\\\ 2.312} & \\makecell{0.863 \\\\ 0.027} & \\makecell{0.029 \\\\ 0.012} & \\makecell{0.837 \\\\ 0.037} & \\makecell{24.484 \\\\ 2.469} & \\makecell{0.720 \\\\ 0.098} \\\\\n",
      "        \\makecell[l]{L1 + PERCEPTUAL + \\\\ STRUCTURAL} & \\makecell{0.024 \\\\ 0.008} & \\makecell{0.841 \\\\ 0.035} & \\makecell{24.550 \\\\ 1.822} & \\makecell{0.864 \\\\ 0.025} & \\makecell{0.025 \\\\ 0.011} & \\makecell{0.842 \\\\ 0.036} & \\makecell{24.616 \\\\ 2.380} & \\makecell{0.841 \\\\ 0.036} \\\\\n",
      "        L1 + STRUCTURAL & \\makecell{0.023 \\\\ 0.011} & \\makecell{0.857 \\\\ 0.036} & \\makecell{24.939 \\\\ 2.472} & \\makecell{0.873 \\\\ 0.024} & \\makecell{0.024 \\\\ 0.011} & \\makecell{0.849 \\\\ 0.035} & \\makecell{25.032 \\\\ 2.555} & \\makecell{0.852 \\\\ 0.035} \\\\\n",
      "        \\bottomrule\n",
      "    \\end{tabular}\n",
      "\\end{table*}\n"
     ]
    }
   ],
   "source": [
    "latex_code = create_latex_table_from_dataframe(summary_results)\n",
    "print(latex_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781a8897",
   "metadata": {},
   "source": [
    "--- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16641691",
   "metadata": {},
   "source": [
    "# Image Generation\n",
    "\n",
    "Vado a produrre le immagini per il paper. In particolare ci sono differenti blocchi : \n",
    "\n",
    "- Comparison Image\n",
    "- 3D stuck visualization\n",
    "- Visualization of predict example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7f436e",
   "metadata": {},
   "source": [
    "## Comparison image\n",
    "\n",
    "Creazione di pannel  per comparazioni immagini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7593be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from monai.transforms import Compose, LoadImage, EnsureChannelFirst, Orientation, Spacing\n",
    "import SimpleITK as sitk\n",
    "\n",
    "\n",
    "\n",
    "def plot_image_comparison(\n",
    "    image_paths: list[str],\n",
    "    image_names: list[str],\n",
    "    output_path: str,\n",
    "    views_to_show: list[str] = [\"Assiale\", \"Coronale\", \"Sagittale\"],\n",
    "    title: str = '',\n",
    "    reorientation: bool = True,\n",
    "    ct_window_level: int = 40,    # NUOVO: Livello della finestra per CT (Soft Tissue)\n",
    "    ct_window_width: int = 60,\n",
    "    windowing : bool = False    # NUOVO: Ampiezza della finestra per CT (Soft Tissue)\n",
    "):\n",
    "    \"\"\"\n",
    "    Carica immagini NIfTI, le preprocessa e genera un confronto.\n",
    "    Applica un windowing specifico per le immagini identificate come 'CT'.\n",
    "    \"\"\"\n",
    "    if len(image_paths) != len(image_names):\n",
    "        raise ValueError(\"La lunghezza di 'image_paths' e 'image_names' deve essere la stessa.\")\n",
    "\n",
    "    transform_list = [\n",
    "        LoadImage(image_only=True, reader=\"nibabelreader\"),\n",
    "        EnsureChannelFirst()\n",
    "    ]\n",
    "    if reorientation:\n",
    "        transform_list.extend([\n",
    "            Orientation(axcodes=\"RAS\"),\n",
    "            Spacing(pixdim=(1.0, 1.0, 1.0), mode=\"bilinear\")\n",
    "        ])\n",
    "    \n",
    "    transforms = Compose(transform_list)\n",
    "\n",
    "    loaded_images = []\n",
    "    for path in image_paths:\n",
    "        try:\n",
    "            img = transforms(path)\n",
    "            if img.dim() == 4:\n",
    "                img = img.squeeze(0)\n",
    "            loaded_images.append(img)\n",
    "            print(f\"Caricata e processata: {os.path.basename(path)}, shape finale: {img.shape}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Errore durante il caricamento di {path}: {e}\")\n",
    "            return\n",
    "\n",
    "    n_rows = len(loaded_images)\n",
    "    n_cols = len(views_to_show)\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(5 * n_cols, 5 * n_rows), facecolor='black', squeeze=False)\n",
    "    fig.suptitle(title, fontsize=20, color='white')\n",
    "    view_to_axis = {\"Sagittale\": 0, \"Coronale\": 1, \"Assiale\": 2}\n",
    "\n",
    "    for i, (img_tensor, img_name) in enumerate(zip(loaded_images, image_names)):\n",
    "        for j, view_name in enumerate(views_to_show):\n",
    "            ax = axes[i, j]\n",
    "            axis_idx = view_to_axis.get(view_name)\n",
    "            if axis_idx is None:\n",
    "                ax.axis('off')\n",
    "                continue\n",
    "\n",
    "            mid_slice_idx = img_tensor.shape[axis_idx] // 2\n",
    "            slice_data = torch.index_select(img_tensor, axis_idx, torch.tensor([mid_slice_idx])).squeeze()\n",
    "            slice_np = slice_data.cpu().numpy()\n",
    "            \n",
    "            if 'ct' in img_name.lower() and windowing :\n",
    "                # Applica il windowing per la CT\n",
    "                min_val = ct_window_level - (ct_window_width / 2)\n",
    "                max_val = ct_window_level + (ct_window_width / 2)\n",
    "                slice_np = np.clip(slice_np, min_val, max_val)\n",
    "            else:\n",
    "                # Applica la normalizzazione con percentile per altre modalità (es. MR)\n",
    "                p_min, p_max = np.percentile(slice_np, [1, 99])\n",
    "                slice_np = np.clip(slice_np, p_min, p_max)\n",
    "            # -----------------------------------------------\n",
    "\n",
    "            ax.imshow(np.rot90(slice_np), cmap='gray', aspect='equal')\n",
    "            ax.axis('off')\n",
    "\n",
    "            if j == 0:\n",
    "                ax.text(-0.1, 0.5, img_name, transform=ax.transAxes, ha='right', va='center', fontsize=16, color='white', rotation=90)\n",
    "            #if i == 0:\n",
    "                #ax.set_title(view_name, fontsize=16, color='white')\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "    \n",
    "    output_dir = os.path.dirname(output_path)\n",
    "    if output_dir:\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "    try:\n",
    "        plt.savefig(output_path, bbox_inches='tight', pad_inches=0.1, facecolor='black', dpi=300)\n",
    "        print(f\"Immagine di confronto salvata in: {output_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Errore durante il salvataggio dell'immagine: {e}\")\n",
    "    \n",
    "    plt.close(fig)\n",
    "\n",
    "def plot_ct_mr_comparison(ct_path: str, mr_path: str, output_path: str):\n",
    "    \"\"\"\n",
    "    Wrapper per la funzione generalizzata per mantenere la retrocompatibilità.\n",
    "    Carica una CT e una MR e genera un'immagine di confronto.\n",
    "\n",
    "    Args:\n",
    "        ct_path (str): Percorso del file NIfTI della CT.\n",
    "        mr_path (str): Percorso del file NIfTI della MR.\n",
    "        output_path (str): Percorso dove salvare l'immagine PNG generata.\n",
    "    \"\"\"\n",
    "    plot_image_comparison(\n",
    "        image_paths=[ct_path, mr_path],\n",
    "        image_names=[\"CT\", \"MR\"],\n",
    "        output_path=output_path,\n",
    "        title='Paired CT and MR sample'\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94cdf053",
   "metadata": {},
   "source": [
    "### CTandMR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a3b19d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plot_ct_mr_comparison' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 165\u001b[39m\n\u001b[32m    163\u001b[39m ct_path = \u001b[33m\"\u001b[39m\u001b[33m/home/jovyan/work/data/CTMR/DATASET/RF/sub-1126260/sub-1126260_ct.nii.gz\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    164\u001b[39m mr_path = \u001b[33m\"\u001b[39m\u001b[33m/home/jovyan/work/data/CTMR/DATASET/RF/sub-1126260/sub-1126260_t1w.nii.gz\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m165\u001b[39m \u001b[43mplot_ct_mr_comparison\u001b[49m(ct_path, mr_path,\u001b[33m\"\u001b[39m\u001b[33m./CTandMR.jpeg\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'plot_ct_mr_comparison' is not defined"
     ]
    }
   ],
   "source": [
    "ct_path = \"/home/jovyan/work/data/CTMR/DATASET/RF/sub-1126260/sub-1126260_ct.nii.gz\"\n",
    "mr_path = \"/home/jovyan/work/data/CTMR/DATASET/RF/sub-1126260/sub-1126260_t1w.nii.gz\"\n",
    "plot_ct_mr_comparison(ct_path, mr_path,\"./CTandMR.jpeg\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c813093",
   "metadata": {},
   "source": [
    "### Generated Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e0f385d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caricata e processata: sub-1126260ctTemplatespace.nii.gz, shape finale: torch.Size([193, 229, 193])\n",
      "Caricata e processata: sub-1126260mrTemplateSpaceNormalized.nii.gz, shape finale: torch.Size([193, 229, 193])\n",
      "Caricata e processata: sub-1126260ctTemplatespace_generated_mr.nii.gz, shape finale: torch.Size([193, 229, 193])\n",
      "Caricata e processata: sub-1126260-ctTemplatespace_generated_mr.nii.gz, shape finale: torch.Size([193, 229, 193])\n",
      "Immagine di confronto salvata in: /home/jovyan/work/repository/CT2MR/Generation_clean/ctTomr_RF.jpeg\n"
     ]
    }
   ],
   "source": [
    "ct_path = \"/home/jovyan/work/data/CTMR/DATASET/RF/sub-1126260/processed/CT/CTonTemplate/sub-1126260ctTemplatespace.nii.gz\"\n",
    "mr_path = \"/home/jovyan/work/data/CTMR/DATASET/RF/sub-1126260/processed/MR/MRonTemplate/sub-1126260mrTemplateSpaceNormalized.nii.gz\"\n",
    "swin_gen = \"/home/jovyan/work/repository/CT2MR/Generation_clean/lightning_logs/CTtoMR/version_1/test_results/RF/sub-1126260/sub-1126260ctTemplatespace_generated_mr.nii.gz\"\n",
    "unet_gen = \"/home/jovyan/work/repository/CT2MR/Generation_clean/lightning_logs/CTtoMR/version_2/test_results/RF/sub-1126260/sub-1126260-ctTemplatespace_generated_mr.nii.gz\"\n",
    "plot_image_comparison([ct_path,mr_path,swin_gen,unet_gen],[\"CT\",\"MR\",\"SwinGen\",\"UnetGen\"],\"/home/jovyan/work/repository/CT2MR/Generation_clean/ctTomr_RF.jpeg\",windowing = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "72e73827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caricata e processata: sub-1126260mrMRCTmasked.nii.gz, shape finale: torch.Size([180, 240, 240])\n",
      "Caricata e processata: sub-1126260ctMRspaceMRCTmasked.nii.gz, shape finale: torch.Size([180, 240, 240])\n",
      "Caricata e processata: sub-1126260mrMRCTmasked_generated_mr.nii.gz, shape finale: torch.Size([180, 240, 240])\n",
      "Caricata e processata: sub-1126260mrMRCTmasked_generated_mr.nii.gz, shape finale: torch.Size([180, 240, 240])\n",
      "Immagine di confronto salvata in: /home/jovyan/work/repository/CT2MR/Generation_clean/mrToct_RF.jpeg\n"
     ]
    }
   ],
   "source": [
    "ct_path = \"/home/jovyan/work/data/CTMR/DATASET/RF/sub-1126260/processed/CT/CTonMR/sub-1126260ctMRspaceMRCTmasked.nii.gz\"\n",
    "mr_path = \"/home/jovyan/work/data/CTMR/DATASET/RF/sub-1126260/processed/MR/sub-1126260mrMRCTmasked.nii.gz\"\n",
    "swin_gen = \"/home/jovyan/work/repository/CT2MR/Generation_clean/lightning_logs/MRtoCT/version_1/test_results/RF/sub-1126260/sub-1126260mrMRCTmasked_generated_mr.nii.gz\"\n",
    "unet_gen = \"/home/jovyan/work/repository/CT2MR/Generation_clean/lightning_logs/MRtoCT/version_2/test_results/RF/sub-1126260/sub-1126260mrMRCTmasked_generated_mr.nii.gz\"\n",
    "plot_image_comparison([mr_path,ct_path,swin_gen,unet_gen],[\"MR\",\"CT\",\"SwinGen\",\"UnetGen\"],\"/home/jovyan/work/repository/CT2MR/Generation_clean/mrToct_RF.jpeg\",windowing = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "42419308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caricata e processata: sub-1BB026-ctTemplatespace.nii.gz, shape finale: torch.Size([193, 229, 193])\n",
      "Caricata e processata: sub-1BB026-mrTemplateSpaceNormalized.nii.gz, shape finale: torch.Size([193, 229, 193])\n",
      "Caricata e processata: sub-1BB026-ctTemplatespace_generated_mr.nii.gz, shape finale: torch.Size([193, 229, 193])\n",
      "Caricata e processata: sub-1BB026-ctTemplatespace_generated_mr.nii.gz, shape finale: torch.Size([193, 229, 193])\n",
      "Immagine di confronto salvata in: /home/jovyan/work/repository/CT2MR/Generation_clean/ctTOmr_synthrad.jpeg\n"
     ]
    }
   ],
   "source": [
    "ct_path = \"/home/jovyan/work/data/CTMR/DATASET/SynthRAD2023/sub-1BB026/processed/CT/CTonTemplate/sub-1BB026-ctTemplatespace.nii.gz\"\n",
    "mr_path = \"/home/jovyan/work/data/CTMR/DATASET/SynthRAD2023/sub-1BB026/processed/MR/MRonTemplate/sub-1BB026-mrTemplateSpaceNormalized.nii.gz\"\n",
    "swin_gen = \"/home/jovyan/work/repository/CT2MR/Generation_clean/lightning_logs/CTtoMR/version_1/test_results/SynthRAD2023/sub-1BB026/sub-1BB026-ctTemplatespace_generated_mr.nii.gz\"\n",
    "unet_gen = \"/home/jovyan/work/repository/CT2MR/Generation_clean/lightning_logs/CTtoMR/version_2/test_results/SynthRAD2023/sub-1BB026/sub-1BB026-ctTemplatespace_generated_mr.nii.gz\"\n",
    "plot_image_comparison([ct_path,mr_path,swin_gen,unet_gen],[\"CT\",\"MR\",\"SwinGen\",\"UnetGen\"],\"/home/jovyan/work/repository/CT2MR/Generation_clean/ctTOmr_synthrad.jpeg\",windowing = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ed55aebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caricata e processata: sub-1BA141mrMRCTmasked.nii.gz, shape finale: torch.Size([183, 257, 190])\n",
      "Caricata e processata: sub-1BA141-ctMRspaceMRCTmasked.nii.gz, shape finale: torch.Size([183, 257, 190])\n",
      "Caricata e processata: sub-1BA141mrMRCTmasked_generated_mr.nii.gz, shape finale: torch.Size([183, 257, 190])\n",
      "Caricata e processata: sub-1BA141mrMRCTmasked_generated_mr.nii.gz, shape finale: torch.Size([183, 257, 190])\n",
      "Immagine di confronto salvata in: /home/jovyan/work/repository/CT2MR/Generation_clean/mrToct_synthrad.jpeg\n"
     ]
    }
   ],
   "source": [
    "ct_path = \"/home/jovyan/work/data/CTMR/DATASET/SynthRAD2023/sub-1BA141/processed/CT/CTonMR/sub-1BA141-ctMRspaceMRCTmasked.nii.gz\"\n",
    "mr_path = \"/home/jovyan/work/data/CTMR/DATASET/SynthRAD2023/sub-1BA141/processed/MR/sub-1BA141mrMRCTmasked.nii.gz\"\n",
    "swin_gen = \"/home/jovyan/work/repository/CT2MR/Generation_clean/lightning_logs/MRtoCT/version_1/test_results/SynthRAD2023/sub-1BA141/sub-1BA141mrMRCTmasked_generated_mr.nii.gz\"\n",
    "unet_gen = \"/home/jovyan/work/repository/CT2MR/Generation_clean/lightning_logs/MRtoCT/version_2/test_results/SynthRAD2023/sub-1BA141/sub-1BA141mrMRCTmasked_generated_mr.nii.gz\"\n",
    "plot_image_comparison([mr_path,ct_path,swin_gen,unet_gen],[\"MR\",\"CT\",\"SwinGen\",\"UnetGen\"],\"/home/jovyan/work/repository/CT2MR/Generation_clean/mrToct_synthrad.jpeg\",windowing = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d6dbbb",
   "metadata": {},
   "source": [
    "## 3D stuck visualization \n",
    "\n",
    "Visualizzazione a \"pila\" di volumi per grafico modello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb16b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import SimpleITK as sitk\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D  \n",
    "from matplotlib.colors import Normalize  \n",
    "from typing import Union, Tuple, Optional\n",
    "\n",
    "from data.datautils import window_image, get_window_viewing_value\n",
    "\n",
    "def plot_slice_stack(volume_3d: np.ndarray, num_slices: int = 20, output_filename: str = \"pila_di_slice.png\", stride: int = 2, windowing: Optional[Union[str, Tuple[float, float]]] = None):\n",
    "    \"\"\"\n",
    "    Crea una visualizzazione 3D di una pila di slice da un volume NumPy 3D.\n",
    "    Questa funzione è CPU-bound a causa di Matplotlib.\n",
    "\n",
    "    Args:\n",
    "        volume_3d (np.ndarray): L'array NumPy 3D da visualizzare. Può anche essere un tensore PyTorch.\n",
    "        num_slices (int): Numero di slice da visualizzare.\n",
    "        output_filename (str): Nome del file per l'immagine di output.\n",
    "        stride (int): Il passo per il campionamento della superficie (qualità vs velocità).\n",
    "        windowing (Optional[Union[str, Tuple[float, float]]]): Applica il windowing.\n",
    "            Può essere una stringa di preset (es. 'brain', 'bone') o una tupla (width, level).\n",
    "            Se None, usa la normalizzazione con percentili.\n",
    "    \"\"\"\n",
    "\n",
    "    if hasattr(volume_3d, 'cpu'): # Controlla se è un tensore PyTorch\n",
    "        print(\"Rilevato tensore PyTorch, spostamento su CPU e conversione in NumPy...\")\n",
    "        volume_3d = volume_3d.cpu().numpy()\n",
    "    \n",
    "\n",
    "    if volume_3d.ndim > 3:\n",
    "        volume_3d = volume_3d.squeeze()\n",
    "        print(f\"Array ridotto a 3 dimensioni, nuova shape: {volume_3d.shape}\")\n",
    "\n",
    "\n",
    "    depth = volume_3d.shape[0]\n",
    "    central_slice_index = depth // 2\n",
    "\n",
    "    slice_indices = np.linspace(0, central_slice_index, num_slices, dtype=int)\n",
    "    selected_slices = volume_3d[slice_indices]\n",
    "\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    windowing_applied = False\n",
    "    if windowing:\n",
    "        print(f\"Applicando windowing: {windowing}\")\n",
    "        if isinstance(windowing, str):\n",
    "            try:\n",
    "                width, level = get_window_viewing_value(windowing)\n",
    "                windowing_applied = True\n",
    "            except ValueError as e:\n",
    "                print(f\"Attenzione: {e}. Ritorno alla normalizzazione con percentili.\")\n",
    "        elif isinstance(windowing, (tuple, list)) and len(windowing) == 2:\n",
    "            width, level = windowing\n",
    "            windowing_applied = True\n",
    "        else:\n",
    "            print(f\"Attenzione: formato 'windowing' non valido. Ritorno alla normalizzazione con percentili.\")\n",
    "        \n",
    "        if windowing_applied:\n",
    "\n",
    "             volume_3d = window_image(volume_3d, window_width=width, window_level=level)\n",
    "             vmin, vmax = np.min(volume_3d), np.max(volume_3d)\n",
    "    \n",
    "    if not windowing_applied:\n",
    "        print(\"Nessun windowing specificato, uso la normalizzazione con percentili.\")\n",
    "        vmin = np.percentile(volume_3d, 1)\n",
    "        vmax = np.percentile(volume_3d, 99)\n",
    "\n",
    "    if vmin == vmax: \n",
    "        vmin, vmax = vmin - 1, vmax + 1\n",
    "    norm = Normalize(vmin=vmin, vmax=vmax)\n",
    "\n",
    "    for i, slice_2d in enumerate(selected_slices):\n",
    "        height, width = slice_2d.shape\n",
    "        x, y = np.meshgrid(np.arange(width), np.arange(height))\n",
    "        z_position = slice_indices[i]\n",
    "        \n",
    "        facecolors = plt.cm.gray(norm(slice_2d))\n",
    "        \n",
    "        ax.plot_surface(x, y, np.full_like(x, z_position),\n",
    "                        facecolors=facecolors, rstride=stride, cstride=stride, shade=False)\n",
    "\n",
    "    ax.set_axis_off()\n",
    "\n",
    "    # 'elev=85' guarda la pila quasi dall'alto.\n",
    "    # 'azim=-90' ruota la vista per allinearla con l'asse.\n",
    "    ax.view_init(elev=85, azim=-90)\n",
    "    ax.dist = 7\n",
    "    plt.savefig(output_filename, dpi=150, transparent=True, bbox_inches='tight', pad_inches=0)\n",
    "    plt.close(fig)\n",
    "    print(f\"✅ Immagine salvata come '{output_filename}'\")\n",
    "\n",
    "def plot_slice_stack_from_file_sitk(image_path: str, num_slices: int = 20, output_filename: str = \"pila_di_slice_sitk.png\", stride: int = 4, windowing: Optional[Union[str, Tuple[float, float]]] = None):\n",
    "    \"\"\"\n",
    "    Funzione wrapper per caricare un'immagine da file con SimpleITK e visualizzarla.\n",
    "\n",
    "    Args:\n",
    "        image_path (str): Percorso del file dell'immagine (es. NIfTI, DICOM).\n",
    "        num_slices (int): Numero di slice da visualizzare.\n",
    "        output_filename (str): Nome del file per l'immagine di output.\n",
    "        stride (int): Il passo per il campionamento della superficie.\n",
    "        windowing (Optional[Union[str, Tuple[float, float]]]): Preset o valori (width, level) per il windowing.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        image = sitk.ReadImage(image_path)\n",
    "        print(f\"Immagine caricata con successo da: '{image_path}'\")\n",
    "        volume_3d = sitk.GetArrayFromImage(image)\n",
    "\n",
    "        plot_slice_stack(volume_3d, num_slices, output_filename, stride, windowing)\n",
    "    except Exception as e:\n",
    "        print(f\" Errore durante il caricamento o la visualizzazione dell'immagine: {e}\")\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "47d23e09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Immagine caricata con successo da: '/home/jovyan/work/data/CTMR/DATASET/RF/sub-1126260/processed/MR/MRonTemplate/sub-1126260mrTemplateSpaceNormalized.nii.gz'\n",
      "Nessun windowing specificato, uso la normalizzazione con percentili.\n",
      "✅ Immagine salvata come 'pila_di_slice_da_sitk.png'\n"
     ]
    }
   ],
   "source": [
    "ct_path = \"/home/jovyan/work/data/CTMR/DATASET/RF/sub-1126260/processed/CT/CTonTemplate/sub-1126260ctTemplatespace.nii.gz\"\n",
    "mr_path = \"/home/jovyan/work/data/CTMR/DATASET/RF/sub-1126260/processed/MR/MRonTemplate/sub-1126260mrTemplateSpaceNormalized.nii.gz\"\n",
    "\n",
    "\n",
    "\n",
    "plot_slice_stack_from_file_sitk(\n",
    "    image_path=mr_path, \n",
    "    num_slices=10, \n",
    "    output_filename=\"pila_di_slice_da_sitk.png\",\n",
    "    stride = 1\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "monai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
